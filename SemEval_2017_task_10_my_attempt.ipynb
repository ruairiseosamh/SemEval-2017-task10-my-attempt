{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F73BJ1lwwiaW"
      },
      "source": [
        "Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiYy3Y-aw6yS"
      },
      "outputs": [],
      "source": [
        "!pip install keybert\n",
        "!pip install nltk\n",
        "!pip install gensim\n",
        "!pip install mendelai-brat-parser\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rWQ7lqMxaS4"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcEhpIyawQaM"
      },
      "outputs": [],
      "source": [
        "from keybert import KeyBERT\n",
        "import os\n",
        "import gensim.downloader\n",
        "from gensim.models import Word2Vec\n",
        "from brat_parser import get_entities_relations_attributes_groups\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "from transformers import BertForSequenceClassification\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qge5YlPckkKO"
      },
      "source": [
        "Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoBI7liVkjiI"
      },
      "outputs": [],
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "\n",
        "def accuracy(preds, labels):\n",
        "  correct = 0\n",
        "  for pred,label in zip(preds,labels):\n",
        "    if pred == label:\n",
        "      correct += 1\n",
        "  return (f\"{round(correct/len(labels)*100,2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQOc6bmIwm1J"
      },
      "source": [
        "Read in Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnzVSt-M4c6i"
      },
      "outputs": [],
      "source": [
        "#!wget -O new_data.zip https://github.com/ScienceIE/scienceie.github.io/raw/master/resources/scienceie2017_train.zip\n",
        "#!unzip /content/new_data.zip\n",
        "\n",
        "!wget -O test_data.zip https://github.com/ScienceIE/scienceie.github.io/raw/master/resources/semeval_articles_test.zip\n",
        "!unzip /content/test_data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al6JeuEwK99P"
      },
      "source": [
        "Task 1 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2JG6HdmwfTX"
      },
      "outputs": [],
      "source": [
        "correct=0\n",
        "total=0\n",
        "kw_model = KeyBERT()\n",
        "for files in os.walk(\"/content/train2/\"):\n",
        "  for smaller_file in files[2]:\n",
        "    if '.txt' in smaller_file:\n",
        "      if smaller_file != 'S0009261413011111.txt':\n",
        "        with open(f\"/content/train2/{smaller_file}\") as f:\n",
        "          doc = f.readlines()\n",
        "        my_keywords = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 2),\n",
        "                      use_maxsum=True, nr_candidates=20, top_n=5)\n",
        "        print(f\"{smaller_file}\")\n",
        "        entities, relations, attributes, groups = get_entities_relations_attributes_groups(f\"/content/train2/{os.path.splitext(smaller_file)[0]}.ann\")\n",
        "        values = entities.values()\n",
        "        for keyword, value in zip(my_keywords,values):\n",
        "          total+=1\n",
        "          #print(f\"{keyword[0][0]}, {value.text}\")\n",
        "          if keyword[0][0] in value.text or value.text in keyword[0][0]:\n",
        "            correct+=1\n",
        "        #print(\"--------------------------\")\n",
        "      else:\n",
        "        break\n",
        "\n",
        "correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_z5OlKswHwA"
      },
      "source": [
        "Task 1 Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkxC6K9ftKpQ",
        "outputId": "6107a314-b7ac-456c-829f-50ed607ff6a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21\n",
            "307\n",
            "Accuracy = 6.84%\n"
          ]
        }
      ],
      "source": [
        "print(correct)\n",
        "print(total)\n",
        "my_accuracy = correct/total\n",
        "print(f\"Accuracy = {round(my_accuracy*100,2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-8kcat9LAA_"
      },
      "source": [
        "Task 2 Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ovni_8pALIET"
      },
      "outputs": [],
      "source": [
        "sentences = []\n",
        "my_vectors = []\n",
        "my_keys = []\n",
        "\n",
        "glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
        "\n",
        "for files in os.walk(\"/content/train2/\"):\n",
        "  for smaller_file in files[2]:\n",
        "    if '.ann' in smaller_file:\n",
        "      if smaller_file != 'S0045782515001231.ann':\n",
        "        print(smaller_file)\n",
        "        entities, relations, attributes, groups = get_entities_relations_attributes_groups(f\"/content/train2/{smaller_file}\")\n",
        "        keys = entities.keys()\n",
        "        values = entities.values()\n",
        "        for key,value in zip(keys, values):\n",
        "          if value.text not in glove_vectors.wv:\n",
        "            vector = glove_vectors.wv['unk']\n",
        "          else:\n",
        "            vector = glove_vectors.wv[value.text]\n",
        "            #count = count+1\n",
        "          my_keys.append(value.type)\n",
        "          my_vectors.append(vector)\n",
        "      else:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCrud3dPvj4W"
      },
      "source": [
        "Task 2 Bert Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5BNUbUovmxP"
      },
      "outputs": [],
      "source": [
        "sentences = []\n",
        "my_vectors = []\n",
        "my_keys = []\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "for files in os.walk(\"/content/train2/\"):\n",
        "  for smaller_file in files[2]:\n",
        "    if '.ann' in smaller_file:\n",
        "      if smaller_file != 'S0045782515001231.ann':\n",
        "        entities, relations, attributes, groups = get_entities_relations_attributes_groups(f\"/content/train2/{smaller_file}\")\n",
        "        keys = entities.keys()\n",
        "        values = entities.values()\n",
        "        for key,value in zip(keys, values):\n",
        "          if value.text not in glove_vectors.wv:\n",
        "            vector = model.encode('unk')\n",
        "          else:\n",
        "            vector = model.encode(value.text)\n",
        "\n",
        "          my_keys.append(value.type)\n",
        "          my_vectors.append(vector)\n",
        "      else:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfPAT-fRlcG_"
      },
      "source": [
        "Get Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSFxy56fu6zQ"
      },
      "source": [
        "Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrCN7PBBYQGl",
        "outputId": "c089c721-4dcd-4c77-fae4-3a991c6835f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task 2 Support Vector Classifier Accuracy = 52.1%\n",
            "Task 2 Base F1 Score = 52.1\n"
          ]
        }
      ],
      "source": [
        "X = my_vectors\n",
        "y = my_keys\n",
        "\n",
        "# dividing X, y into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
        "\n",
        "preds = OneVsOneClassifier(LinearSVC(random_state=0)).fit(X, y).predict(X)\n",
        "\n",
        "my_accuracy = accuracy(preds, my_keys)\n",
        "\n",
        "print(f\"Task 2 Support Vector Classifier Accuracy = {my_accuracy}\")\n",
        "\n",
        "my_f1_score = f1_score(y, preds, average='micro')\n",
        "print(f\"Task 2 Base F1 Score = {round(my_f1_score*100,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLLgZH0PlbdF",
        "outputId": "8a3c16ab-564d-4e68-af11-a1b52a7d5d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task 2 Base F1 Score = 0.38\n"
          ]
        }
      ],
      "source": [
        "base_preds = []\n",
        "for _ in preds:\n",
        "  base_preds.append(\"Material\")\n",
        "\n",
        "base_accuracy = accuracy(base_preds, my_keys)\n",
        "my_f1_score = f1_score(y, base_preds, average='micro')\n",
        "print(f\"Task 2 Base F1 Score = {round(my_f1_score,2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx8qMsZlsewW"
      },
      "source": [
        "Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAz2wBxEp51o",
        "outputId": "5a5d8e7a-1c3c-4bb1-be5a-01cffc0c4006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task 2 Decision Tree F1 Score = 49.27\n"
          ]
        }
      ],
      "source": [
        "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X, y)\n",
        "dtree_predictions = dtree_model.predict(X)\n",
        "\n",
        "dtree_accuracy = accuracy(dtree_predictions, my_keys)\n",
        "\n",
        "my_f1_score = f1_score(y, dtree_predictions, average='micro')\n",
        "print(f\"Task 2 Decision Tree F1 Score = {round(my_f1_score*100,2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5rGVsdjvP1-"
      },
      "source": [
        "Confusion Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXmoT3kulWjd",
        "outputId": "1e711097-328f-427c-eb91-c342998f4b76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 68, 299,   0],\n",
              "       [  0, 424,   0],\n",
              "       [  0, 158,   5]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix = confusion_matrix(y, preds)\n",
        "matrix.diagonal()/matrix.sum(axis=1)\n",
        "\n",
        "matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt5aRQSLuJag"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(matrix, annot=True, fmt='2', cmap='Blues')\n",
        "\n",
        "ax.set_title('Support Vector Classifier with BERT Embeddings\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['Task','Process', 'Material'])\n",
        "ax.yaxis.set_ticklabels(['Task','Process', 'Material'])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SemEval 2017 task 10 my attempt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
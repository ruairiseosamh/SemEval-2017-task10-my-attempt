{"cells":[{"cell_type":"markdown","metadata":{"id":"F73BJ1lwwiaW"},"source":["Installs"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27326,"status":"ok","timestamp":1654182881912,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"NiYy3Y-aw6yS","outputId":"c599056e-3325-4ac4-bf49-6f1a44d93fb5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keybert in /usr/local/lib/python3.7/dist-packages (0.5.1)\n","Requirement already satisfied: numpy\u003e=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.21.6)\n","Requirement already satisfied: scikit-learn\u003e=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.0.2)\n","Requirement already satisfied: rich\u003e=10.4.0 in /usr/local/lib/python3.7/dist-packages (from keybert) (12.4.4)\n","Requirement already satisfied: sentence-transformers\u003e=0.3.8 in /usr/local/lib/python3.7/dist-packages (from keybert) (2.2.0)\n","Requirement already satisfied: typing-extensions\u003c5.0,\u003e=4.0.0 in /usr/local/lib/python3.7/dist-packages (from rich\u003e=10.4.0-\u003ekeybert) (4.2.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich\u003e=10.4.0-\u003ekeybert) (2.6.1)\n","Requirement already satisfied: commonmark\u003c0.10.0,\u003e=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich\u003e=10.4.0-\u003ekeybert) (0.9.1)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.22.2-\u003ekeybert) (3.1.0)\n","Requirement already satisfied: scipy\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.22.2-\u003ekeybert) (1.4.1)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.22.2-\u003ekeybert) (1.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers\u003e=0.3.8-\u003ekeybert) (4.64.0)\n","Requirement already satisfied: torch\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers\u003e=0.3.8-\u003ekeybert) (1.11.0+cu113)\n","Requirement already satisfied: transformers\u003c5.0.0,\u003e=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers\u003e=0.3.8-\u003ekeybert) (4.19.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers\u003e=0.3.8-\u003ekeybert) (3.2.5)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers\u003e=0.3.8-\u003ekeybert) (0.12.0+cu113)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers\u003e=0.3.8-\u003ekeybert) (0.7.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers\u003e=0.3.8-\u003ekeybert) (0.1.96)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (2019.12.20)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (4.11.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (3.7.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (3.8.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (1.15.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (2022.5.18.1)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (1.24.3)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision-\u003esentence-transformers\u003e=0.3.8-\u003ekeybert) (7.1.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: scipy\u003e=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: six\u003e=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: numpy\u003e=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n","Requirement already satisfied: smart-open\u003e=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: mendelai-brat-parser in /usr/local/lib/python3.7/dist-packages (0.0.11)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n","Requirement already satisfied: transformers\u003c5.0.0,\u003e=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.19.2)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.7.0)\n","Requirement already satisfied: torch\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.11.0+cu113)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.12.0+cu113)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch\u003e=1.6.0-\u003esentence-transformers) (4.2.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (4.11.4)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (0.12.1)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (3.8.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk-\u003esentence-transformers) (1.15.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (2022.5.18.1)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers\u003c5.0.0,\u003e=4.6.0-\u003esentence-transformers) (2.10)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003esentence-transformers) (3.1.0)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003esentence-transformers) (1.1.0)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision-\u003esentence-transformers) (7.1.2)\n"]}],"source":["!pip install keybert\n","!pip install nltk\n","!pip install gensim\n","!pip install mendelai-brat-parser\n","!pip install -U sentence-transformers"]},{"cell_type":"markdown","metadata":{"id":"-rWQ7lqMxaS4"},"source":["Imports"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654182887030,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"pcEhpIyawQaM"},"outputs":[],"source":["from keybert import KeyBERT\n","import os\n","import gensim.downloader\n","from gensim.models import Word2Vec\n","from brat_parser import get_entities_relations_attributes_groups\n","import torch\n","from tqdm.notebook import tqdm\n","from transformers import BertTokenizer\n","from torch.utils.data import TensorDataset\n","from transformers import BertForSequenceClassification\n","from sklearn.metrics import f1_score\n","import numpy as np\n","from sklearn.svm import LinearSVC\n","from sklearn.multiclass import OneVsOneClassifier\n","from sklearn.metrics import f1_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{"id":"Qge5YlPckkKO"},"source":["Evaluation Functions"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":616,"status":"ok","timestamp":1654182892863,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"zoBI7liVkjiI"},"outputs":[],"source":["def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')\n","\n","def accuracy_per_class(preds, labels):\n","    label_dict_inverse = {v: k for k, v in label_dict.items()}\n","    \n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","\n","def accuracy(preds, labels):\n","  correct = 0\n","  for pred,label in zip(preds,labels):\n","    if pred == label:\n","      correct += 1\n","  return (f\"{round(correct/len(labels)*100,2)}%\")"]},{"cell_type":"markdown","metadata":{"id":"dQOc6bmIwm1J"},"source":["Read in Files"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1372,"status":"ok","timestamp":1654182898404,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"xnzVSt-M4c6i","outputId":"1623a1cd-d24f-4ad2-9261-533a13e347df"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-06-02 15:13:14--  https://github.com/ScienceIE/scienceie.github.io/raw/master/resources/semeval_articles_test.zip\n","Resolving github.com (github.com)... 52.192.72.89\n","Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/ScienceIE/scienceie.github.io/master/resources/semeval_articles_test.zip [following]\n","--2022-06-02 15:13:14--  https://raw.githubusercontent.com/ScienceIE/scienceie.github.io/master/resources/semeval_articles_test.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 146325 (143K) [application/zip]\n","Saving to: ‘test_data.zip’\n","\n","test_data.zip       100%[===================\u003e] 142.90K  --.-KB/s    in 0.03s   \n","\n","2022-06-02 15:13:15 (4.92 MB/s) - ‘test_data.zip’ saved [146325/146325]\n","\n","Archive:  /content/test_data.zip\n","   creating: semeval_articles_test/\n","  inflating: semeval_articles_test/S0010482516301810.ann  \n","  inflating: semeval_articles_test/S0010482516301810.txt  \n","  inflating: semeval_articles_test/S0010938X15301268.ann  \n","  inflating: semeval_articles_test/S0010938X15301268.txt  \n","  inflating: semeval_articles_test/S0010938X15301554.ann  \n","  inflating: semeval_articles_test/S0010938X15301554.txt  \n","  inflating: semeval_articles_test/S0011227514002136.ann  \n","  inflating: semeval_articles_test/S0011227514002136.txt  \n","  inflating: semeval_articles_test/S0011227515000648.ann  \n","  inflating: semeval_articles_test/S0011227515000648.txt  \n","  inflating: semeval_articles_test/S0011227515001216.ann  \n","  inflating: semeval_articles_test/S0011227515001216.txt  \n","  inflating: semeval_articles_test/S002002551630384X.ann  \n","  inflating: semeval_articles_test/S002002551630384X.txt  \n","  inflating: semeval_articles_test/S0021961414003255.ann  \n","  inflating: semeval_articles_test/S0021961414003255.txt  \n","  inflating: semeval_articles_test/S002199911200068X.ann  \n","  inflating: semeval_articles_test/S002199911200068X.txt  \n","  inflating: semeval_articles_test/S0021999112002847.ann  \n","  inflating: semeval_articles_test/S0021999112002847.txt  \n","  inflating: semeval_articles_test/S0021999112003579.ann  \n","  inflating: semeval_articles_test/S0021999112003579.txt  \n","  inflating: semeval_articles_test/S0021999113002945.ann  \n","  inflating: semeval_articles_test/S0021999113002945.txt  \n","  inflating: semeval_articles_test/S0021999113003422.ann  \n","  inflating: semeval_articles_test/S0021999113003422.txt  \n","  inflating: semeval_articles_test/S002199911300346X.ann  \n","  inflating: semeval_articles_test/S002199911300346X.txt  \n","  inflating: semeval_articles_test/S0021999113004555.ann  \n","  inflating: semeval_articles_test/S0021999113004555.txt  \n","  inflating: semeval_articles_test/S0021999113005603.ann  \n","  inflating: semeval_articles_test/S0021999113005603.txt  \n","  inflating: semeval_articles_test/S0021999113005652.ann  \n","  inflating: semeval_articles_test/S0021999113005652.txt  \n","  inflating: semeval_articles_test/S0021999113005718.ann  \n","  inflating: semeval_articles_test/S0021999113005718.txt  \n","  inflating: semeval_articles_test/S0021999113006955.ann  \n","  inflating: semeval_articles_test/S0021999113006955.txt  \n","  inflating: semeval_articles_test/S0021999116303291.ann  \n","  inflating: semeval_articles_test/S0021999116303291.txt  \n","  inflating: semeval_articles_test/S0032386107010518.ann  \n","  inflating: semeval_articles_test/S0032386107010518.txt  \n","  inflating: semeval_articles_test/S0032386108009397.ann  \n","  inflating: semeval_articles_test/S0032386108009397.txt  \n","  inflating: semeval_articles_test/S0032386109001463.ann  \n","  inflating: semeval_articles_test/S0032386109001463.txt  \n","  inflating: semeval_articles_test/S0032386109003991.ann  \n","  inflating: semeval_articles_test/S0032386109003991.txt  \n","  inflating: semeval_articles_test/S0032386109005357.ann  \n","  inflating: semeval_articles_test/S0032386109005357.txt  \n","  inflating: semeval_articles_test/S0032386110001254.ann  \n","  inflating: semeval_articles_test/S0032386110001254.txt  \n","  inflating: semeval_articles_test/S0039602899010493.ann  \n","  inflating: semeval_articles_test/S0039602899010493.txt  \n","  inflating: semeval_articles_test/S0098300413002124.ann  \n","  inflating: semeval_articles_test/S0098300413002124.txt  \n","  inflating: semeval_articles_test/S0098300414000259.ann  \n","  inflating: semeval_articles_test/S0098300414000259.txt  \n","  inflating: semeval_articles_test/S0098300414002532.ann  \n","  inflating: semeval_articles_test/S0098300414002532.txt  \n","  inflating: semeval_articles_test/S0166361516300926.ann  \n","  inflating: semeval_articles_test/S0166361516300926.txt  \n","  inflating: semeval_articles_test/S0168365912007560.ann  \n","  inflating: semeval_articles_test/S0168365912007560.txt  \n","  inflating: semeval_articles_test/S0168365913001521.ann  \n","  inflating: semeval_articles_test/S0168365913001521.txt  \n","  inflating: semeval_articles_test/S0168365913009589.ann  \n","  inflating: semeval_articles_test/S0168365913009589.txt  \n","  inflating: semeval_articles_test/S0168583X14003929.ann  \n","  inflating: semeval_articles_test/S0168583X14003929.txt  \n","  inflating: semeval_articles_test/S0257897213003563.ann  \n","  inflating: semeval_articles_test/S0257897213003563.txt  \n","  inflating: semeval_articles_test/S0257897213004131.ann  \n","  inflating: semeval_articles_test/S0257897213004131.txt  \n","  inflating: semeval_articles_test/S0263822312000657.ann  \n","  inflating: semeval_articles_test/S0263822312000657.txt  \n","  inflating: semeval_articles_test/S0263822312001468.ann  \n","  inflating: semeval_articles_test/S0263822312001468.txt  \n","  inflating: semeval_articles_test/S0301679X13003289.ann  \n","  inflating: semeval_articles_test/S0301679X13003289.txt  \n","  inflating: semeval_articles_test/S0301679X14000449.ann  \n","  inflating: semeval_articles_test/S0301679X14000449.txt  \n","  inflating: semeval_articles_test/S0301679X14003272.ann  \n","  inflating: semeval_articles_test/S0301679X14003272.txt  \n","  inflating: semeval_articles_test/S0304399111001811.ann  \n","  inflating: semeval_articles_test/S0304399111001811.txt  \n","  inflating: semeval_articles_test/S030439911200040X.ann  \n","  inflating: semeval_articles_test/S030439911200040X.txt  \n","  inflating: semeval_articles_test/S0305440314001927.ann  \n","  inflating: semeval_articles_test/S0305440314001927.txt  \n","  inflating: semeval_articles_test/S0370269301015222.ann  \n","  inflating: semeval_articles_test/S0370269301015222.txt  \n","  inflating: semeval_articles_test/S0370269302011838.ann  \n","  inflating: semeval_articles_test/S0370269302011838.txt  \n","  inflating: semeval_articles_test/S0370269302012492.ann  \n","  inflating: semeval_articles_test/S0370269302012492.txt  \n","  inflating: semeval_articles_test/S0370269302013412.ann  \n","  inflating: semeval_articles_test/S0370269302013412.txt  \n","  inflating: semeval_articles_test/S0370269302014880.ann  \n","  inflating: semeval_articles_test/S0370269302014880.txt  \n","  inflating: semeval_articles_test/S0370269302014892.ann  \n","  inflating: semeval_articles_test/S0370269302014892.txt  \n","  inflating: semeval_articles_test/S0370269303015478.ann  \n","  inflating: semeval_articles_test/S0370269303015478.txt  \n","  inflating: semeval_articles_test/S0370269303017222.ann  \n","  inflating: semeval_articles_test/S0370269303017222.txt  \n","  inflating: semeval_articles_test/S037026930301801X.ann  \n","  inflating: semeval_articles_test/S037026930301801X.txt  \n","  inflating: semeval_articles_test/S0370269304005829.ann  \n","  inflating: semeval_articles_test/S0370269304005829.txt  \n","  inflating: semeval_articles_test/S0370269304007567.ann  \n","  inflating: semeval_articles_test/S0370269304007567.txt  \n","  inflating: semeval_articles_test/S0370269304007816.ann  \n","  inflating: semeval_articles_test/S0370269304007816.txt  \n","  inflating: semeval_articles_test/S0370269304008421.ann  \n","  inflating: semeval_articles_test/S0370269304008421.txt  \n","  inflating: semeval_articles_test/S0370269304008494.ann  \n","  inflating: semeval_articles_test/S0370269304008494.txt  \n","  inflating: semeval_articles_test/S0370269304009293.ann  \n","  inflating: semeval_articles_test/S0370269304009293.txt  \n","  inflating: semeval_articles_test/S0370269304012638.ann  \n","  inflating: semeval_articles_test/S0370269304012638.txt  \n","  inflating: semeval_articles_test/S037877531001949X.ann  \n","  inflating: semeval_articles_test/S037877531001949X.txt  \n","  inflating: semeval_articles_test/S0885230816301759.ann  \n","  inflating: semeval_articles_test/S0885230816301759.txt  \n","  inflating: semeval_articles_test/S092583881302834X.ann  \n","  inflating: semeval_articles_test/S092583881302834X.txt  \n","  inflating: semeval_articles_test/S0925838814009669.ann  \n","  inflating: semeval_articles_test/S0925838814009669.txt  \n","  inflating: semeval_articles_test/S0927025614003322.ann  \n","  inflating: semeval_articles_test/S0927025614003322.txt  \n","  inflating: semeval_articles_test/S0927025614006181.ann  \n","  inflating: semeval_articles_test/S0927025614006181.txt  \n","  inflating: semeval_articles_test/S0927025615006357.ann  \n","  inflating: semeval_articles_test/S0927025615006357.txt  \n","  inflating: semeval_articles_test/S096386951400070X.ann  \n","  inflating: semeval_articles_test/S096386951400070X.txt  \n","  inflating: semeval_articles_test/S0963869514000875.ann  \n","  inflating: semeval_articles_test/S0963869514000875.txt  \n","  inflating: semeval_articles_test/S0963869514000954.ann  \n","  inflating: semeval_articles_test/S0963869514000954.txt  \n","  inflating: semeval_articles_test/S0963869514001066.ann  \n","  inflating: semeval_articles_test/S0963869514001066.txt  \n","  inflating: semeval_articles_test/S0963869514001078.ann  \n","  inflating: semeval_articles_test/S0963869514001078.txt  \n","  inflating: semeval_articles_test/S0963869515000572.ann  \n","  inflating: semeval_articles_test/S0963869515000572.txt  \n","  inflating: semeval_articles_test/S0968432814000250.ann  \n","  inflating: semeval_articles_test/S0968432814000250.txt  \n","  inflating: semeval_articles_test/S1010603009002676.ann  \n","  inflating: semeval_articles_test/S1010603009002676.txt  \n","  inflating: semeval_articles_test/S1010603013001809.ann  \n","  inflating: semeval_articles_test/S1010603013001809.txt  \n","  inflating: semeval_articles_test/S107158191630074X.ann  \n","  inflating: semeval_articles_test/S107158191630074X.txt  \n","  inflating: semeval_articles_test/S1359646214000165.ann  \n","  inflating: semeval_articles_test/S1359646214000165.txt  \n","  inflating: semeval_articles_test/S1364815216302122.ann  \n","  inflating: semeval_articles_test/S1364815216302122.txt  \n","  inflating: semeval_articles_test/S1364815216302705.ann  \n","  inflating: semeval_articles_test/S1364815216302705.txt  \n","  inflating: semeval_articles_test/S136481521630305X.ann  \n","  inflating: semeval_articles_test/S136481521630305X.txt  \n","  inflating: semeval_articles_test/S1364815216303061.ann  \n","  inflating: semeval_articles_test/S1364815216303061.txt  \n","  inflating: semeval_articles_test/S1364815216303243.ann  \n","  inflating: semeval_articles_test/S1364815216303243.txt  \n","  inflating: semeval_articles_test/S1386505616301769.ann  \n","  inflating: semeval_articles_test/S1386505616301769.txt  \n","  inflating: semeval_articles_test/S1574119211001544.ann  \n","  inflating: semeval_articles_test/S1574119211001544.txt  \n","  inflating: semeval_articles_test/S1574119215000796.ann  \n","  inflating: semeval_articles_test/S1574119215000796.txt  \n","  inflating: semeval_articles_test/S1631070514000954.ann  \n","  inflating: semeval_articles_test/S1631070514000954.txt  \n","  inflating: semeval_articles_test/S167420011300196X.ann  \n","  inflating: semeval_articles_test/S167420011300196X.txt  \n","  inflating: semeval_articles_test/S1687850714000405.ann  \n","  inflating: semeval_articles_test/S1687850714000405.txt  \n","  inflating: semeval_articles_test/S1746809416300933.ann  \n","  inflating: semeval_articles_test/S1746809416300933.txt  \n","  inflating: semeval_articles_test/S1877750311000676.ann  \n","  inflating: semeval_articles_test/S1877750311000676.txt  \n","  inflating: semeval_articles_test/S1877750313000240.ann  \n","  inflating: semeval_articles_test/S1877750313000240.txt  \n","  inflating: semeval_articles_test/S187775031300077X.ann  \n","  inflating: semeval_articles_test/S187775031300077X.txt  \n","  inflating: semeval_articles_test/S1877750313001269.ann  \n","  inflating: semeval_articles_test/S1877750313001269.txt  \n","  inflating: semeval_articles_test/S1877750315000460.ann  \n","  inflating: semeval_articles_test/S1877750315000460.txt  \n","  inflating: semeval_articles_test/S2212671612000431.ann  \n","  inflating: semeval_articles_test/S2212671612000431.txt  \n","  inflating: semeval_articles_test/S2212671612000741.ann  \n","  inflating: semeval_articles_test/S2212671612000741.txt  \n","  inflating: semeval_articles_test/S221267161400105X.ann  \n","  inflating: semeval_articles_test/S221267161400105X.txt  \n","  inflating: semeval_articles_test/S221450951400014X.ann  \n","  inflating: semeval_articles_test/S221450951400014X.txt  \n"]}],"source":["#!wget -O new_data.zip https://github.com/ScienceIE/scienceie.github.io/raw/master/resources/scienceie2017_train.zip\n","#!unzip /content/new_data.zip\n","\n","!wget -O test_data.zip https://github.com/ScienceIE/scienceie.github.io/raw/master/resources/semeval_articles_test.zip\n","!unzip /content/test_data.zip"]},{"cell_type":"markdown","metadata":{"id":"Al6JeuEwK99P"},"source":["Task 1 Model"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":203593,"status":"ok","timestamp":1654183105573,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"A2JG6HdmwfTX","outputId":"d22a7720-9ab4-4f73-fe66-cb1ef7828631"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n","1it [00:00, 105.01it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0098300413002720.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 233.86it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612000704.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 272.23it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0032386110004039.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 596.63it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009359.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 188.73it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0301010414003516.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 194.55it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167273814004408.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 223.01it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999114002587.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 182.40it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0032386109004996.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 508.34it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814001361.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 120.54it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000070.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 558.72it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S074756321630348X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 155.80it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000550.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 175.40it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0029549314002970.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 187.36it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0165212511000862.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 189.33it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000331.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 187.61it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0031920113001222.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 129.12it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304007439.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 192.59it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304006161.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 355.06it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999114007396.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 131.97it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814001476.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 257.05it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S092702561300267X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 172.31it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0003491615001955.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 238.18it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667812000822.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 301.12it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0378381215300674.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 414.99it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0166218X1300348X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 401.29it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612002302.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 387.04it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X13002187.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 332.88it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0032386109007290.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 201.15it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0009261412006513.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 633.01it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370157312000105.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 215.78it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S025405841530136X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 213.83it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0032386109006612.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 168.89it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931713004061.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 763.57it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667812000536.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 354.25it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0378381215301291.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 345.47it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0032386109005485.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 216.17it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2214657115000155.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 194.89it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304007749.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 170.07it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S1570870516301822.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 172.51it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377221716304258.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 173.28it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X14000420.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 683.89it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009220.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 315.43it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0009261415002730.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 327.48it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931712003012.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 152.51it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931712002699.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 379.09it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304007798.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 396.89it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0393044012000198.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 379.16it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S016793171300244X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 190.25it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0888613X16301062.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 360.46it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612002338.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 252.55it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0375960112002885.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 331.25it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311515002664.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 137.53it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612001291.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 161.99it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0039602899010869.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 401.71it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999114007876.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 192.79it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612001709.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 223.62it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000884.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 191.17it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999114008432.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 183.29it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782512002678.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 215.03it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0168365913009036.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 162.37it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612000698.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 279.75it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311515300295.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 214.83it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S1566253516300069.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 234.36it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782515002686.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 118.32it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782513000546.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 262.92it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2214509515300103.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 286.24it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S003238610801080X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 325.06it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0038092X15000559.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 256.42it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311514000919.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 161.13it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304006756.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 293.76it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009232.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 329.79it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667812000883.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 142.78it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667812000524.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 356.05it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009141.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 140.59it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0038092X15001681.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 126.98it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612001163.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 145.21it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0895611116300684.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 247.95it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370157314001318.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 272.04it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782514000607.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 248.32it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2214657115000052.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 159.56it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782514001492.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 171.27it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304008305.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 205.10it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931714004456.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 358.21it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304006720.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 297.72it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X12001163.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 167.86it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311513001165.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 359.16it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167273811005091.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 247.54it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0009261412012365.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 163.32it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0375960115005630.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 133.68it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0168365913003295.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 145.29it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S221450951530005X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 211.37it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S221266781400080X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 256.72it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782513001448.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 280.84it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0003491615001505.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 166.26it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667813001068.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 127.83it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0375960113006725.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 263.00it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009530.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 284.71it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0166218X14003011.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 139.98it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S1361841516300822.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 121.38it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0165168416300603.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 704.93it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S221267161200162X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 140.79it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304008731.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 186.11it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0098300412001793.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 384.02it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000045.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 235.46it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X1530161X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 280.46it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0168365912006207.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 244.10it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931714000203.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 169.84it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0885230816300043.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 140.08it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931713002487.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 397.53it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0098300413002185.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 129.11it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999115001412.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 157.15it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999115008256.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 176.52it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304007634.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 165.57it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667812000664.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 115.78it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0375960113004908.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 340.03it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S221266781400121X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 266.68it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S1364815216303541.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 677.81it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667813000762.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 235.56it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0301010415002256.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 579.96it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S037596011300741X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 149.77it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311513011951.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 151.53it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0254058415001212.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 253.86it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0301932215002037.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 381.16it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009049.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 142.62it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S088523081530036X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 167.16it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931713002438.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 166.83it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000756.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 165.07it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612002181.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 218.86it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S221266781200007X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 224.61it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0031920113000708.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 199.24it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0032386108010392.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 376.88it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X12002508.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 159.49it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931713006904.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 288.07it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X13005945.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 205.90it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377221716303873.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 135.30it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377025714001682.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 147.44it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311514008691.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 341.89it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667813000610.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 601.16it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0306437913000768.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 245.64it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S1875952116300209.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 298.68it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S000926141500651X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 253.36it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311515300830.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 182.89it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0305054816300867.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 617.81it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311511010014.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 447.11it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0165212515000931.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 158.44it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0736585316300661.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 152.59it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S221267161200176X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 261.98it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999114008523.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 161.99it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0029549314001551.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 228.42it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377221716300984.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 350.64it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S000926141301539X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 170.98it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304007701.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 293.39it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377025714000317.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 162.97it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612002375.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 144.25it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311515300477.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 172.99it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377221716301904.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 163.25it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X15301189.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 155.72it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304008792.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 154.09it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167273815004130.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 557.31it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0957417416303773.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 247.66it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021961413004321.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 148.14it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782513000479.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 232.44it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0266352X16301550.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 527.59it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370157309002877.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 273.08it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311515301963.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 396.14it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009013.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 129.84it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0957417416302561.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 357.39it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0927025614007137.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 154.16it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009104.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 314.77it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0142061516308079.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 151.52it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377025715000993.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 137.61it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782512000266.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 419.22it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612001692.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 122.12it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S1361841516300342.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 207.63it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814001294.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 115.36it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009347.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 398.32it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009074.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 180.75it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999113005652.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 146.99it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0963869514000863.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 141.58it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999115000546.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 145.98it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X15002085.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 348.42it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0375960113010839.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 295.39it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782512003428.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 422.43it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931711005120.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 140.43it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009979.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 337.33it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667813000774.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 198.93it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377025715000051.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 657.93it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009657.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 117.45it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X1500195X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 210.81it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782513001473.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 93.26it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304007208.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 208.21it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0032386114008428.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 547.27it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0032386109001712.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 240.49it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667812000792.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 173.53it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782512003234.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 397.68it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009037.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 183.38it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999115007238.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 203.14it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377221716302259.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 122.06it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0038092X14004770.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 329.04it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009165.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 218.25it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009335.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 185.83it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009268.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 411.77it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0957417416301786.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 122.44it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931713004991.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 142.99it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931714003347.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 368.24it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0032386109010386.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 150.10it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0379711213001653.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 147.71it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S037026930400930X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 158.40it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612000121.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 144.34it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999113005603.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 133.57it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999113003422.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 416.80it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0888327016300048.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 181.53it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311515301069.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 175.93it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311514007119.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 151.20it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304008809.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 228.31it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931713005042.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 154.32it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667812000780.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 169.32it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0038092X11004129.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 145.28it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311514006849.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 341.42it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0098300413002951.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 146.44it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311515303640.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 139.32it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377221716301357.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 258.75it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782515002418.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 139.87it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X15002954.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 174.02it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0254058414000662.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 145.82it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0009261413006738.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 133.54it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304008998.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 263.88it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000264.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 134.41it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0168365913004975.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 262.95it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814001348.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 454.37it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0997754612001318.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 290.04it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000732.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 295.98it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377025714000135.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 199.13it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377025713001031.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 196.78it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0168874X1630049X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 157.59it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667812000810.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 221.71it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S002231151500032X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 152.35it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S092702561300760X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 149.09it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667812000032.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 173.08it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009062.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 132.63it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0168365913008766.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 131.55it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304007695.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 420.78it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999115003939.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 182.81it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304008780.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 223.89it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S221266781300083X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 167.32it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2352179114200032.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 155.34it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000124.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 156.96it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667812000949.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 121.88it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000975.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 149.34it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814001464.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 148.86it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009803.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 441.78it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814001488.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 434.24it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S221267161200217X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 137.94it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167931712003905.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 315.27it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304006082.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 186.75it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0009261415000974.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 135.88it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311514001640.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 139.78it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009116.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 103.88it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304008706.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 185.22it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782515001899.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 421.28it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009086.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 146.05it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999113005718.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 135.54it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311514005480.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 110.30it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304006768.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 142.48it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0377025714002213.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 347.84it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0749603615302184.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 309.59it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S037026930400680X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 227.74it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999115008207.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 383.43it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S221266781300018X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 238.10it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009189.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 220.97it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311515002391.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 175.52it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0010938X15300512.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 117.69it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S221266781400149X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 210.72it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304007257.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 213.23it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167273814004548.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 288.21it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0022311515002470.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 152.25it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304006070.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 204.79it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167273813006735.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 150.43it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782512002599.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 267.14it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814001440.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 155.69it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782515003680.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 482.71it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0888613X16300767.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 159.22it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0301010414003115.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 221.93it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304008858.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 218.86it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0021999115003459.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 719.31it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612001497.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 128.07it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0301932214001499.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 140.55it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S003238610900086X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 156.40it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782511003823.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 179.37it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612000686.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 361.14it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612000716.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 136.39it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000069.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 111.81it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S004578251400334X.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 225.20it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0927025612000249.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 133.28it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612001618.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 376.00it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212667814000380.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 180.45it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304009025.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 138.62it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0079642514000887.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 153.28it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612000637.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 332.22it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612002120.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 157.82it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0009261412013838.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 294.67it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S2212671612002351.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 131.40it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0370269304008974.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 398.36it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0045782514004812.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 129.53it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0003491615000433.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 189.57it/s]\n","/usr/local/lib/python3.7/dist-packages/keybert/_model.py:131: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n","  \"Although extracting keywords for multiple documents is faster \"\n"]},{"name":"stdout","output_type":"stream","text":["S0167273812003025.txt\n"]},{"name":"stderr","output_type":"stream","text":["1it [00:00, 180.92it/s]"]},{"name":"stdout","output_type":"stream","text":["S0032386109007423.txt\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["21"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["correct=0\n","total=0\n","kw_model = KeyBERT()\n","for files in os.walk(\"/content/train2/\"):\n","  for smaller_file in files[2]:\n","    if '.txt' in smaller_file:\n","      if smaller_file != 'S0009261413011111.txt':\n","        with open(f\"/content/train2/{smaller_file}\") as f:\n","          doc = f.readlines()\n","        my_keywords = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 2),\n","                      use_maxsum=True, nr_candidates=20, top_n=5)\n","        print(f\"{smaller_file}\")\n","        entities, relations, attributes, groups = get_entities_relations_attributes_groups(f\"/content/train2/{os.path.splitext(smaller_file)[0]}.ann\")\n","        values = entities.values()\n","        for keyword, value in zip(my_keywords,values):\n","          total+=1\n","          #print(f\"{keyword[0][0]}, {value.text}\")\n","          if keyword[0][0] in value.text or value.text in keyword[0][0]:\n","            correct+=1\n","        #print(\"--------------------------\")\n","      else:\n","        break\n","\n","correct"]},{"cell_type":"markdown","metadata":{"id":"c_z5OlKswHwA"},"source":["Task 1 Evaluation"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":510,"status":"ok","timestamp":1654183120397,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"CkxC6K9ftKpQ","outputId":"6107a314-b7ac-456c-829f-50ed607ff6a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["21\n","307\n","Accuracy = 6.84%\n"]}],"source":["print(correct)\n","print(total)\n","my_accuracy = correct/total\n","print(f\"Accuracy = {round(my_accuracy*100,2)}%\")"]},{"cell_type":"markdown","metadata":{"id":"B-8kcat9LAA_"},"source":["Task 2 Glove Embeddings"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25614,"status":"ok","timestamp":1654183147951,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"ovni_8pALIET"},"outputs":[{"name":"stdout","output_type":"stream","text":["S0029549314001551.ann\n","S2212667814000987.ann\n","S2212667814000951.ann\n","S0167273812003025.ann\n","S0098300413002185.ann\n","S0370269304007208.ann\n","S0009261409006666.ann\n","S0167931714000203.ann\n","S0370269304007695.ann\n","S0888613X16300767.ann\n","S0168874X1630049X.ann\n","S2212667813000762.ann\n","S0003491615000433.ann\n","S0010938X15300512.ann\n","S221450951530005X.ann\n","S0370269304009141.ann\n","S0370269304008998.ann\n","S2212671612002338.ann\n","S0167931714003347.ann\n","S0370269304006768.ann\n","S0022311514007119.ann\n","S0167931714004456.ann\n","S0167273813005298.ann\n","S2212667814001348.ann\n","S0370269304007439.ann\n","S0377025714000317.ann\n","S2212667812000937.ann\n","S037026930400930X.ann\n","S0032386109007423.ann\n","S0022311515002664.ann\n","S0377221716300984.ann\n","S0022311515301963.ann\n","S0370269304007701.ann\n","S0168365913004975.ann\n","S0045782513000479.ann\n","S0045782513001448.ann\n","S2212671612000613.ann\n","S0022311515300477.ann\n","S0021999114008432.ann\n","S0370269304009165.ann\n","S0377221716302259.ann\n","S2212667813000774.ann\n","S0370269304009803.ann\n","S0305054816300867.ann\n","S0370269304007257.ann\n","S030193221400144X.ann\n","S2212667812000524.ann\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"]}],"source":["sentences = []\n","my_vectors = []\n","my_keys = []\n","\n","glove_vectors = gensim.downloader.load('glove-twitter-25')\n","\n","for files in os.walk(\"/content/train2/\"):\n","  for smaller_file in files[2]:\n","    if '.ann' in smaller_file:\n","      if smaller_file != 'S0045782515001231.ann':\n","        print(smaller_file)\n","        entities, relations, attributes, groups = get_entities_relations_attributes_groups(f\"/content/train2/{smaller_file}\")\n","        keys = entities.keys()\n","        values = entities.values()\n","        for key,value in zip(keys, values):\n","          if value.text not in glove_vectors.wv:\n","            vector = glove_vectors.wv['unk']\n","          else:\n","            vector = glove_vectors.wv[value.text]\n","            #count = count+1\n","          my_keys.append(value.type)\n","          my_vectors.append(vector)\n","      else:\n","        break"]},{"cell_type":"markdown","metadata":{"id":"MCrud3dPvj4W"},"source":["Task 2 Bert Embeddings"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23774,"status":"ok","timestamp":1654183188609,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"b5BNUbUovmxP","outputId":"7ba07b87-5df8-4baa-be11-bb2b83407657"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  from ipykernel import kernelapp as app\n"]}],"source":["sentences = []\n","my_vectors = []\n","my_keys = []\n","\n","model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","for files in os.walk(\"/content/train2/\"):\n","  for smaller_file in files[2]:\n","    if '.ann' in smaller_file:\n","      if smaller_file != 'S0045782515001231.ann':\n","        entities, relations, attributes, groups = get_entities_relations_attributes_groups(f\"/content/train2/{smaller_file}\")\n","        keys = entities.keys()\n","        values = entities.values()\n","        for key,value in zip(keys, values):\n","          if value.text not in glove_vectors.wv:\n","            vector = model.encode('unk')\n","          else:\n","            vector = model.encode(value.text)\n","\n","          my_keys.append(value.type)\n","          my_vectors.append(vector)\n","      else:\n","        break"]},{"cell_type":"markdown","metadata":{"id":"dfPAT-fRlcG_"},"source":["Get Baseline"]},{"cell_type":"markdown","metadata":{"id":"bSFxy56fu6zQ"},"source":["Support Vector Classifier"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1654183196484,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"rrCN7PBBYQGl","outputId":"c089c721-4dcd-4c77-fae4-3a991c6835f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Task 2 Support Vector Classifier Accuracy = 52.1%\n","Task 2 Base F1 Score = 52.1\n"]}],"source":["X = my_vectors\n","y = my_keys\n","\n","# dividing X, y into train and test data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n","\n","preds = OneVsOneClassifier(LinearSVC(random_state=0)).fit(X, y).predict(X)\n","\n","my_accuracy = accuracy(preds, my_keys)\n","\n","print(f\"Task 2 Support Vector Classifier Accuracy = {my_accuracy}\")\n","\n","my_f1_score = f1_score(y, preds, average='micro')\n","print(f\"Task 2 Base F1 Score = {round(my_f1_score*100,2)}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1654183206404,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"nLLgZH0PlbdF","outputId":"8a3c16ab-564d-4e68-af11-a1b52a7d5d6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Task 2 Base F1 Score = 0.38\n"]}],"source":["base_preds = []\n","for _ in preds:\n","  base_preds.append(\"Material\")\n","\n","base_accuracy = accuracy(base_preds, my_keys)\n","my_f1_score = f1_score(y, base_preds, average='micro')\n","print(f\"Task 2 Base F1 Score = {round(my_f1_score,2)}\")"]},{"cell_type":"markdown","metadata":{"id":"dx8qMsZlsewW"},"source":["Decision Tree Classifier"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654183212099,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"eAz2wBxEp51o","outputId":"5a5d8e7a-1c3c-4bb1-be5a-01cffc0c4006"},"outputs":[{"name":"stdout","output_type":"stream","text":["Task 2 Decision Tree F1 Score = 49.27\n"]}],"source":["dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X, y)\n","dtree_predictions = dtree_model.predict(X)\n","\n","dtree_accuracy = accuracy(dtree_predictions, my_keys)\n","\n","my_f1_score = f1_score(y, dtree_predictions, average='micro')\n","print(f\"Task 2 Decision Tree F1 Score = {round(my_f1_score*100,2)}\")"]},{"cell_type":"markdown","metadata":{"id":"m5rGVsdjvP1-"},"source":["Confusion Matrices"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":617,"status":"ok","timestamp":1654183219012,"user":{"displayName":"Fatemeh Amerehi","userId":"09826330131130146882"},"user_tz":-60},"id":"jXmoT3kulWjd","outputId":"1e711097-328f-427c-eb91-c342998f4b76"},"outputs":[{"data":{"text/plain":["array([[ 68, 299,   0],\n","       [  0, 424,   0],\n","       [  0, 158,   5]])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["matrix = confusion_matrix(y, preds)\n","matrix.diagonal()/matrix.sum(axis=1)\n","\n","matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":926,"status":"ok","timestamp":1654182677822,"user":{"displayName":"Rory Ward","userId":"01188596469118037682"},"user_tz":-60},"id":"Zt5aRQSLuJag","outputId":"de5bf526-0b8f-4b4f-dede-42df1e37d3ce"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 2 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["ax = sns.heatmap(matrix, annot=True, fmt='2', cmap='Blues')\n","\n","ax.set_title('Support Vector Classifier with BERT Embeddings\\n\\n');\n","ax.set_xlabel('\\nPredicted Values')\n","ax.set_ylabel('Actual Values ');\n","\n","## Ticket labels - List must be in alphabetical order\n","ax.xaxis.set_ticklabels(['Task','Process', 'Material'])\n","ax.yaxis.set_ticklabels(['Task','Process', 'Material'])\n","\n","## Display the visualization of the Confusion Matrix.\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"NLP Group 6.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}